<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on wudao的博客</title>
    <link>https://wudaore.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on wudao的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 05 Jun 2022 00:00:00 +0800</lastBuildDate><atom:link href="https://wudaore.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>决策树学习</title>
      <link>https://wudaore.github.io/post/decision-tree/</link>
      <pubDate>Sun, 05 Jun 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/decision-tree/</guid>
      <description>目录 基本原理 信息熵和信息增益 总结 ps. 1. 基本原理 决策树是一种树形结构，每个内部节点代表一个属性上的判断.每个叶节点代表一种分类结果.它的本质就是基于数据，通过问一系列的问题(if-else)去预测结果。 2.</description>
    </item>
    
    <item>
      <title>逻辑回归学习</title>
      <link>https://wudaore.github.io/post/logistic-regression/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/logistic-regression/</guid>
      <description>目录 基本原理 逻辑回归的损失函数 逻辑回归的优化 随机梯度上升 分类评估方法 sklearn实现 总结 ps. 1. 基本原理 虽然叫回归但是其实解决的是二分类问题.逻辑回归的输入值为线性回归的输出值，即 之所以能解决二分类问题</description>
    </item>
    
    <item>
      <title>线性回归学习</title>
      <link>https://wudaore.github.io/post/linear-regression/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/linear-regression/</guid>
      <description>目录 基本原理 线性回归的损失优化 局部加权线性回归 正则化线性模型 逐步向前回归 sklearn用法 总结 ps. 1. 基本原理 1.1 分类和回归 区别在于分类问题是定性的，输出离散值（如+1，-1）.而回归问题是定量的，输出连续</description>
    </item>
    
    <item>
      <title>KNN学习</title>
      <link>https://wudaore.github.io/post/knn/</link>
      <pubDate>Sun, 29 May 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/knn/</guid>
      <description>Introduction 基本原理 各种距离 距离调参 KNN优化-KD树 数据处理（归一化和标准化） 实战&amp;ndash;鸢尾花数据集 总结 1. 基本原理 非常朴素的原理。根据距离最近的K个点来判断目标点的类别. 2. 各种距离 标准距离 汉明距离 杰卡</description>
    </item>
    
    <item>
      <title>matplotlib基础</title>
      <link>https://wudaore.github.io/post/hello_matplotlib/</link>
      <pubDate>Tue, 24 May 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/hello_matplotlib/</guid>
      <description>Introduction 对matplotlib的简易学习 import matplotlib.pyplot as plt import random matplotlib图像的绘制 # 1. 创建画布 # figsize 画布大小 dpi 像素 plt.figure(figsize=(20, 8), dpi=100) # 2.图像绘制 x = [1,2,3,4,5,6] y = [3,6,3,5,3,10] plt.plot(x, y) # 3.图像展示 plt.show() # help(plt.figure) 图像保存 # 1. 创建画布 plt.figure(figsize=(20, 8), dpi=100) # 2.图像绘</description>
    </item>
    
    <item>
      <title>svm学习(1)--基础概念和公式</title>
      <link>https://wudaore.github.io/post/svm1/</link>
      <pubDate>Fri, 13 May 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/svm1/</guid>
      <description>Introduction &amp;laquo;实战&amp;raquo;中的svm数学推导实在是有些晦涩难懂. bilibili视频教程：https://www.bilibili.com/video/BV1Hs411w7ci?spm_id_</description>
    </item>
    
    <item>
      <title>svm学习(2)--简易SMO算法代码理解</title>
      <link>https://wudaore.github.io/post/svm2/</link>
      <pubDate>Fri, 13 May 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/svm2/</guid>
      <description>Introduction SMO算法 即序列最小优化算法 对&amp;laquo;实战&amp;raquo;中的smoSimple函数尝试理解 def smoSimple(dataMatIn, classLabels, C, toler, maxIter): &amp;quot;&amp;quot;&amp;quot;smoSimple Args: dataMatIn 特征集合 classLabels 类别标签 C 松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。 控制</description>
    </item>
    
    <item>
      <title>svm学习(3)--SVM实现鸢尾花数据分类</title>
      <link>https://wudaore.github.io/post/svm3/</link>
      <pubDate>Fri, 13 May 2022 00:00:00 +0800</pubDate>
      
      <guid>https://wudaore.github.io/post/svm3/</guid>
      <description>Introduction sklearn的SVM算法可以调整c值和核函数.本篇并未介绍核函数 导入数据和数据-标签的处理 from sklearn.svm import SVC from sklearn import datasets iris = datasets.load_iris() X = iris[&#39;data&#39;] X = iris[&#39;data&#39;][:,(2,3)] y = iris[&#39;target&#39;] SVM训练.c值设置为无穷大代表几乎不容错 使用线性核函数 setosa_or_versicolor = (y==0)|(y==1) X =</description>
    </item>
    
  </channel>
</rss>
