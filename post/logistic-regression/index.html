<!DOCTYPE html>
<html lang="en">

<head>
    
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.98.0" />


<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn-main@1/images/favicons/dsrca.ico" />



<title>逻辑回归学习 - wudao的博客</title>


<meta name="author" content="DSRKafuU" />


<meta name="description" content="A minimal Hugo theme with nice theme color." />


<meta name="keywords" content="机器学习, algo" />


<meta property="og:title" content="逻辑回归学习" />
<meta name="twitter:title" content="逻辑回归学习" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wudaore.github.io/post/logistic-regression/" /><meta property="og:description" content="目录 基本原理 逻辑回归的损失函数 逻辑回归的优化 随机梯度上升 分类评估方法 sklearn实现 ps. 1. 基本原理 虽然叫回归但是其实解决的是二分类问题.逻辑回归的输入值为线性回归的输出值，即 之所以能解决二分类问题，是" />
<meta name="twitter:description" content="目录 基本原理 逻辑回归的损失函数 逻辑回归的优化 随机梯度上升 分类评估方法 sklearn实现 ps. 1. 基本原理 虽然叫回归但是其实解决的是二分类问题.逻辑回归的输入值为线性回归的输出值，即 之所以能解决二分类问题，是" /><meta property="og:image" content="https://wudaore.github.io/img/og.png" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://wudaore.github.io/img/og.png" /><meta property="article:published_time" content="2022-06-03T00:00:00+08:00" /><meta property="article:modified_time" content="2022-06-03T00:00:00+08:00" />


<style>
    @media (prefers-color-scheme: dark) {
        body[data-theme='auto'] img {
            filter: brightness(60%);
        }
    }

    body[data-theme='dark'] img {
        filter: brightness(60%);
    }
</style>




<link rel="stylesheet" href="https://wudaore.github.io/assets/css/fuji.min.css" />








</head>

<body
  data-theme="auto"
  data-theme-auto='true'
  >
    <script data-cfasync="false">
  
  var fujiThemeData = localStorage.getItem('fuji_data-theme');
  
  if (!fujiThemeData) {
    localStorage.setItem('fuji_data-theme', 'auto');
  } else {
    
    if (fujiThemeData !== 'auto') {
      document.body.setAttribute('data-theme', fujiThemeData === 'dark' ? 'dark' : 'light');
    }
  }
</script>

    <header>
    <div class="container-lg clearfix">
        <div class="col-12 header">
            <a class="title-main" href="https://wudaore.github.io/">wudao的博客</a>
            
            <span class="title-sub">钝学累功,不妨精熟</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-12 col-md-9 float-left content">
                
<article>
    
    <h2 class="post-item post-title">
        <a href="https://wudaore.github.io/post/logistic-regression/">逻辑回归学习</a>
    </h2>
    <div class="post-item post-meta">
        <span><i class="iconfont icon-today-sharp"></i>&nbsp;2022-06-03</span>

<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;2447 words</span>

<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;<a href="/tags/algo">algo</a>&nbsp;</span>

    </div>
    
    <div class="post-content markdown-body">
        <h1 id="目录">目录</h1>
<h4 id="基本原理1"><a href="#1">基本原理</a></h4>
<h4 id="逻辑回归的损失函数2"><a href="#2">逻辑回归的损失函数</a></h4>
<h4 id="逻辑回归的优化3"><a href="#3">逻辑回归的优化</a></h4>
<h4 id="随机梯度上升4"><a href="#4">随机梯度上升</a></h4>
<h4 id="分类评估方法45"><a href="#4.5">分类评估方法</a></h4>
<h4 id="sklearn实现5"><a href="#5">sklearn实现</a></h4>
<h4 id="psfinal"><a href="#final">ps.</a></h4>
<h2 id="1-基本原理a-id1a">1. 基本原理<a id="1"></a></h2>
<p>虽然叫回归但是其实解决的是二分类问题.逻辑回归的输入值为线性回归的输出值，即</p>
<p><img class="img-zoomable" src="/logistic/1.png" alt="png" />
</p>
<p>之所以能解决二分类问题，是因为逻辑回归将输入赋予sigmod函数，并设置阈值，可以达到分类的效果</p>
<p><img class="img-zoomable" src="/logistic/2.png" alt="png" />
</p>
<p>sigmod函数：</p>
<p><img class="img-zoomable" src="/logistic/3.png" alt="png" />
</p>
<p>逻辑回归的工作流程如下：</p>
<p><img class="img-zoomable" src="/logistic/4.png" alt="png" />
</p>
<h2 id="2-对数似然函数a-id2a">2. 对数似然函数<a id="2"></a></h2>
<p>区别于线性回归的平方损失函数，逻辑回归使用对数似然函数.</p>
<p><img class="img-zoomable" src="/logistic/5.png" alt="png" />
</p>
<p>也可以这么写（综合完整损失函数.）</p>
<p><img class="img-zoomable" src="/logistic/6.png" alt="png" />
</p>
<p>为什么要使用这个损失函数呢？试想：当样本值（y）为1而线性回归预估值比较小（比如h(θ)接近0）时，通过对数似然函数进行计算，会得到一个很大的值，给予模型最大的惩罚力度；当样本值（y）为1而线性回归预估值比较大（比如h(θ)接近1）时，计算得出0，不给模型惩罚.就很巧妙.</p>
<h2 id="3-逻辑回归的优化a-id3a">3. 逻辑回归的优化<a id="3"></a></h2>
<p>根据上面的综合完整损失函数，可以推导出损失函数的优化是这样的：要使求和的值最小，就要提升原本是类别1的概率，降低原本是类别0的概率.</p>
<p>同样可以使用梯度下降（上升）进行优化.</p>
<p>需要注意的是 《实战》中并没有具体推导对数似然函数的优化过程.以下是推导过程：</p>
<p><img class="img-zoomable" src="/logistic/7.png" alt="png" />
</p>
<p>于是，《实战》中梯度上升的代码就能被解释了.</p>
<pre><code># 梯度上升迭代参数
def gradAscent(dataMatIn, classLabels):
    dataMatrix = mat(dataMatIn)             #convert to NumPy matrix
    labelMat = mat(classLabels).transpose() #转置.
    m,n = shape(dataMatrix)
    alpha = 0.001
    maxCycles = 500
    weights = ones((n,1))
    for k in range(maxCycles):              #maxCycles 迭代次数
        h = sigmoid(dataMatrix*weights)     #matrix mult
        error = (labelMat - h)              #vector subtraction
        weights = weights + alpha * dataMatrix.transpose()* error # 上面推导出的结果
    return weights

</code></pre>
<pre><code># 画出最优曲线
def plotBestFit(weights):
    import matplotlib.pyplot as plt
    dataMat,labelMat=loadDataSet()
    dataArr = array(dataMat)
    n = shape(dataArr)[0] 
    xcord1 = []; ycord1 = []
    xcord2 = []; ycord2 = []
    for i in range(n):
        if int(labelMat[i])== 1:
            xcord1.append(dataArr[i,1])
            ycord1.append(dataArr[i,2])
        else:
            xcord2.append(dataArr[i,1])
            ycord2.append(dataArr[i,2])
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(xcord1, ycord1, s=30, c='blue', marker='s')
    ax.scatter(xcord2, ycord2, s=30, c='green')
    x = arange(-3.0, 3.0, 0.1)
    # 这里的Y其实是X2. 须知y=xw，x0=0，而根据sigmod函数图像，当xw=0时可以分割两类曲线.因此0=xw，可以推导出x1和x2（这里的Y）的关系
    y = (-weights[0]-weights[1]*x)/weights[2]
    ax.plot(x, y)
    plt.xlabel('X1'); plt.ylabel('X2');
    plt.show()

</code></pre>
<h2 id="4-随机的梯度上升-a-id4a">4. 随机的梯度上升 <a id="4"></a></h2>
<p>gradAscent中dataMatrix * weights是矩阵相乘，实际进行了300次，即需要遍历整个数据集，在数据集很大时效率不好.需要进行优化.</p>
<p>使用随机梯度上升，每次只计算一个数据的梯度而非整个数据集，可以达到更快的速度.</p>
<pre><code>
# 随机梯度上升迭代参数
def stocGradAscent0(dataMatrix, classLabels):
    m,n = shape(dataMatrix)
    alpha = 0.01
    weights = ones(n)   #initialize to all ones
    for i in range(m):
        h = sigmoid(sum(dataMatrix[i]*weights))
        error = classLabels[i] - h
        weights = weights + alpha * error * dataMatrix[i]
    return weights
</code></pre>
<p>当存在非线性可分的点时，会导致出现较大的波动。另外，需要加快收敛速度.故而引入改进的随机梯度上升.</p>
<pre><code>
def stocGradAscent1(dataMatrix, classLabels, numIter=150):
    m,n = shape(dataMatrix)
    weights = ones(n)   #initialize to all ones
    for j in range(numIter):
        dataIndex = range(m)
        for i in range(m):
            alpha = 4/(1.0+j+i)+0.0001    #apha decreases with iteration, does not 
            randIndex = int(random.uniform(0,len(dataIndex)))#go to 0 because of the constant
            h = sigmoid(sum(dataMatrix[randIndex]*weights))
            error = classLabels[randIndex] - h
            weights = weights + alpha * error * dataMatrix[randIndex]
            del(dataIndex[randIndex])
    return weights

</code></pre>
<p>alpha = 4/(1.0+j+i)+0.0001 是为了让α随迭代逐步减小到逼近0.（但是并不是严格单调递减）</p>
<p>另外，区别于上个算法，这个算法使用随机的样本来更新权重系数，这样做的好处是能能够减少周期波动.</p>
<h2 id="5分类评估方法-a-id45a">5.分类评估方法 <a id="4.5"></a></h2>
<p>混淆矩阵：</p>
<p><img class="img-zoomable" src="/logistic/9.png" alt="png" />
</p>
<p>其中TP和TN是正确预测的.</p>
<p><strong>准确率(accuracy)：含义为所有样本中预测正确的占比</strong> (TP+TN) / (TP+TN+FP+FN)</p>
<p><strong>精确率(precision)：含义为预测为正例的样本中真实为正的占比，代表查的准不准</strong> (TP) / (TP+FP)</p>
<p><strong>召回率(recall)：含义为真实为正例中预测为正的占比，表示对正样本的区分能力，查的全不全</strong> (TP) / (TP+FN)</p>
<p><strong>F1-score：含义为模型的稳健性</strong> (2TP) / (2TP+FN+FP) = 2<em>precision</em>recall / recall+precision</p>
<p>这些评估方法在sklearn中的实现如下图所示：</p>
<p><img class="img-zoomable" src="/logistic/10.png" alt="png" />
</p>
<p><strong>真阳率TPR，即召回率：含义为检测出来的真阳性样本数除以所有真实阳性样本数</strong> (TP) / (TP+FN)</p>
<p><strong>假阳率FPR：含义为检测出来的假阳性样本数除以所有真实阴性样本数</strong> (FP) / (TN+FP)</p>
<p><strong>ROC曲线：x轴为FPR，y轴为TPR.当预测所有样本为1时，曲线的结果为中间的虚线.</strong></p>
<p><img class="img-zoomable" src="/logistic/11.png" alt="png" />
</p>
<p><strong>AUC指标，即随机取一样本，正样本大于负样本的概率.范围在[0.5,1]之间.当为1时为完美分类器.这个指标一般用于不平衡二分类问题</strong></p>
<p>需要注意的是，在sklearn中使用AUC计算API时，必须0为反例1为正例（一般取样本多的为正例，比如本实验中，4代表恶性，样本多，取为1）.</p>
<p><img class="img-zoomable" src="/logistic/12.png" alt="png" />
</p>
<p>ROC曲线的绘制过程如下：</p>
<p>1.先将各个点的概率从高到低排序.</p>
<p>2.挑选最高的，<strong>假设</strong>其为正例.如果其概率大于阈值，那么就是真正例，否则就是假正例.每次挑选，都要就是那个FPR和TPR</p>
<p>3.迭代直到所有点都求出TPR和FPR.在轴上描点，结果就是ROC曲线.如下图所示，取阈值为0.75</p>
<p><img class="img-zoomable" src="/logistic/13.png" alt="png" />
</p>
<p>AUC其实就是ROC曲线的积分，也即面积.其表示分对的概率</p>
<h2 id="6-sklearn实现-a-id5a">6. sklearn实现 <a id="5"></a></h2>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" target="_blank">sklearn-linearRegression</a></p>
<p>下面是该api的一些常见参数</p>
<p>其中penalty 有L1和L2，详见线性回归的博客；C代表正则化力度，C越大，惩罚越大；solver代表使用的梯度下降算法.</p>
<p><img class="img-zoomable" src="/logistic/8.png" alt="png" />
</p>
<pre><code>import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score

# 1.获取数据
# 2.基本数据处理
# 2.1 缺失值处理
# 2.2 确定特征值,目标值
# 2.3 分割数据
# 3.特征工程(标准化)
# 4.机器学习(逻辑回归)
# 5.模型评估

# 1.获取数据
names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',
                   'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',
                   'Normal Nucleoli', 'Mitoses', 'Class']
data = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;,names=names)

# 2.基本数据处理
# 2.1 缺失值处理
data = data.replace(to_replace=&quot;?&quot;, value=np.nan)
data = data.dropna()

x = data.iloc[:, 1:-1]
y = data[&quot;Class&quot;]

# 2.3 分割数据
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=2, test_size=0.2)

# 3.特征工程(标准化)
transfer = StandardScaler()
x_train = transfer.fit_transform(x_train)
x_test = transfer.fit_transform(x_test)

# 4.机器学习(逻辑回归)
estimator = LogisticRegression()
estimator.fit(x_train, y_train)

# 5.模型评估
# 5.1 基本评估
y_pre = estimator.predict(x_test)
print(&quot;预测值是：\n&quot;, y_pre)
score = estimator.score(x_test, y_test)
print(&quot;准确率是：\n&quot;, score)

# 5.2 其他评估
ret = classification_report(y_test, y_pre, labels=(2,4), target_names=(&quot;良性&quot;, &quot;恶性&quot;))
print(ret)

# 不平衡二分类问题评估方法
y_test = np.where(y_test&gt;3, 1, 0)

roc_auc_score(y_true=y_test, y_score=y_pre)
</code></pre>
<h2 id="7ps-a-idfinala">7.ps. <a id="final"></a></h2>
<p><strong>numpy中mat.getA 将矩阵转换为ndarray</strong></p>
<p><strong>ones((n, 1))，n代表几行，1代表每行有一个数.</strong></p>
<p><strong>关于loc和iloc</strong></p>
<p>前者是根据标签索引进行查找，后者是根据整数索引进行查找.</p>
<p>使用案例：</p>
<pre><code>df.loc([['a','j'], ['name','score']]) #定位行索引值为a，j和列索引值为name和score的dataframe
df.iloc([[0,9],[0,2]]) #定位第0,9行，第0,2列的dataframe

# 切片用法，loc前后都闭合，而iloc前闭后开
df.loc(['a':'j', 'name':'score']) #定位行索引值为a到j和列索引值为name到score的dataframe
df.iloc([0:9,0:2]) #定位第0到8行，第0到1列的dataframe

</code></pre>
<p><strong><a href="https://blog.csdn.net/W_weiying/article/details/84626260" target="_blank">drop的用法</a></strong></p>
<p>像本案例的情况 还是使用replace更好</p>

    </div>
</article>


<div class="license markdown-body">
    <blockquote>
        <p>Unless otherwise noted, the content of this site is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"
               target="_blank">CC BY-NC-SA 4.0</a>.</p>
    </blockquote>
</div>



            </div>
            <aside class="col-12 col-md-3 float-left sidebar">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives/">Archives</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/search/">Search</a>
            </li>
            
            <li>
                <a href="/index.xml">RSS</a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
            <li>
                <a href="https://github.com/dsrkafuu" target="_blank"><span>GitHub</span></a>
            </li>
            
            <li>
                <a href="https://twitter.com/dsrkafuu" target="_blank"><span>Twitter</span></a>
            </li>
            
            <li>
                <a href="https://space.bilibili.com/19767474" target="_blank"><span>bilibili</span></a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/algo/">algo</a>
            </span>
            
            <span>
                <a href="/tags/aplayer/">aplayer</a>
            </span>
            
            <span>
                <a href="/tags/cjk/">cjk</a>
            </span>
            
            <span>
                <a href="/tags/css/">css</a>
            </span>
            
            <span>
                <a href="/tags/emoji/">emoji</a>
            </span>
            
            <span>
                <a href="/tags/html/">html</a>
            </span>
            
            <span>
                <a href="/tags/linux/">linux</a>
            </span>
            
            <span>
                <a href="/tags/markdown/">markdown</a>
            </span>
            
            <span>
                <a href="/tags/others/">others</a>
            </span>
            
            <span>
                <a href="/tags/test/">test</a>
            </span>
            
            <span>
                <a href="/tags/text/">text</a>
            </span>
            
            <span>
                <a href="/tags/themes/">themes</a>
            </span>
            
            <span>
                <a href="/tags/wtf/">wtf</a>
            </span>
            
            <span>
                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
            </span>
            
        </div>
    </div>
    <div class="sidebar-item sidebar-toc">
        <h3>Table of Contents</h3><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#1-基本原理a-id1a">1. 基本原理<a id="1"></a></a></li>
    <li><a href="#2-对数似然函数a-id2a">2. 对数似然函数<a id="2"></a></a></li>
    <li><a href="#3-逻辑回归的优化a-id3a">3. 逻辑回归的优化<a id="3"></a></a></li>
    <li><a href="#4-随机的梯度上升-a-id4a">4. 随机的梯度上升 <a id="4"></a></a></li>
    <li><a href="#5分类评估方法-a-id45a">5.分类评估方法 <a id="4.5"></a></a></li>
    <li><a href="#6-sklearn实现-a-id5a">6. sklearn实现 <a id="5"></a></a></li>
    <li><a href="#7ps-a-idfinala">7.ps. <a id="final"></a></a></li>
  </ul>
</nav></div>
</aside>

        </div>
        <div class="btn">
    <div class="btn-menu" id="btn-menu">
        <i class="iconfont icon-grid-sharp"></i>
    </div>
    <div class="btn-toggle-mode">
        <i class="iconfont icon-contrast-sharp"></i>
    </div>
    <div class="btn-scroll-top">
        <i class="iconfont icon-chevron-up-circle-sharp"></i>
    </div>
</div>
<aside class="sidebar-mobile" style="display: none;">
  <div class="sidebar-wrapper">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives/">Archives</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/search/">Search</a>
            </li>
            
            <li>
                <a href="/index.xml">RSS</a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
            <li>
                <a href="https://github.com/dsrkafuu" target="_blank"><span>GitHub</span></a>
            </li>
            
            <li>
                <a href="https://twitter.com/dsrkafuu" target="_blank"><span>Twitter</span></a>
            </li>
            
            <li>
                <a href="https://space.bilibili.com/19767474" target="_blank"><span>bilibili</span></a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/algo/">algo</a>
            </span>
            
            <span>
                <a href="/tags/aplayer/">aplayer</a>
            </span>
            
            <span>
                <a href="/tags/cjk/">cjk</a>
            </span>
            
            <span>
                <a href="/tags/css/">css</a>
            </span>
            
            <span>
                <a href="/tags/emoji/">emoji</a>
            </span>
            
            <span>
                <a href="/tags/html/">html</a>
            </span>
            
            <span>
                <a href="/tags/linux/">linux</a>
            </span>
            
            <span>
                <a href="/tags/markdown/">markdown</a>
            </span>
            
            <span>
                <a href="/tags/others/">others</a>
            </span>
            
            <span>
                <a href="/tags/test/">test</a>
            </span>
            
            <span>
                <a href="/tags/text/">text</a>
            </span>
            
            <span>
                <a href="/tags/themes/">themes</a>
            </span>
            
            <span>
                <a href="/tags/wtf/">wtf</a>
            </span>
            
            <span>
                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
            </span>
            
        </div>
    </div>
    
    
    
    <div class="sidebar-item sidebar-toc">
        <h3>Table of Contents</h3>
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#1-基本原理a-id1a">1. 基本原理<a id="1"></a></a></li>
    <li><a href="#2-对数似然函数a-id2a">2. 对数似然函数<a id="2"></a></a></li>
    <li><a href="#3-逻辑回归的优化a-id3a">3. 逻辑回归的优化<a id="3"></a></a></li>
    <li><a href="#4-随机的梯度上升-a-id4a">4. 随机的梯度上升 <a id="4"></a></a></li>
    <li><a href="#5分类评估方法-a-id45a">5.分类评估方法 <a id="4.5"></a></a></li>
    <li><a href="#6-sklearn实现-a-id5a">6. sklearn实现 <a id="5"></a></a></li>
    <li><a href="#7ps-a-idfinala">7.ps. <a id="final"></a></a></li>
  </ul>
</nav>
    </div>
    
    
  </div>
</aside>
    </main>

    <footer>
    <div class="container-lg clearfix">
        <div class="col-12 footer">
            
            <span>&copy; 2020-2022
                <a href="https://wudaore.github.io/">DSRKafuU</a>
                 | <a href="https://github.com/dsrkafuu/hugo-theme-fuji">Source code</a> 
                | Powered by <a href="https://github.com/dsrkafuu/hugo-theme-fuji/"
                   target="_blank">Fuji-v2</a> &amp; <a href="https://gohugo.io/"
                                                    target="_blank">Hugo</a> 
            </span>
        </div>
    </div>
</footer>

    
<script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js"></script>



<script defer src="/assets/js/fuji.min.js"></script>



</body>

</html>
